{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O Tools - 외부 데이터를 DataFrame으로 Import 하기\n",
    "실제 데이터 분석에서, 사용할 데이터를 일일히 입력해 넣는 경우는 흔하지 않다.\n",
    "분석에 사용할 데이터는 파일로부터 import를 하는 경우가 대부분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv 파일 DataFrame에 불러오기\n",
    "### 서울시 지하철 승차정보 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           사용일자  노선명   역ID    역명  승차총승객수  하차총승객수      등록일자\n",
      "0      20190801  분당선  1872    매교    2348    2405  20190804\n",
      "1      20190801  분당선  1871  수원시청   11930   13290  20190804\n",
      "2      20190801  분당선  1870  매탄권선    4609    4360  20190804\n",
      "3      20190801  분당선  1869    망포   14103   13044  20190804\n",
      "4      20190801  분당선  1868    영통    9303    9380  20190804\n",
      "...         ...  ...   ...   ...     ...     ...       ...\n",
      "18314  20190831  3호선   316   독립문    8877    8761  20190903\n",
      "18315  20190831  3호선   315   무악재    3491    3576  20190903\n",
      "18316  20190831  3호선   314    홍제   17306   16129  20190903\n",
      "18317  20190831  3호선   313    녹번   11970    9936  20190903\n",
      "18318  20190831  3호선   312    불광   16697   18805  20190903\n",
      "\n",
      "[18319 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://github.com/silent0402/lecturenote/raw/master/Notes/data/subway.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특정 Column만 선택하여 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          사용일자  노선명    역명  승차총승객수  하차총승객수      등록일자\n",
      "역ID                                                \n",
      "1872  20190801  분당선    매교    2348    2405  20190804\n",
      "1871  20190801  분당선  수원시청   11930   13290  20190804\n",
      "1870  20190801  분당선  매탄권선    4609    4360  20190804\n",
      "1869  20190801  분당선    망포   14103   13044  20190804\n",
      "1868  20190801  분당선    영통    9303    9380  20190804\n",
      "...        ...  ...   ...     ...     ...       ...\n",
      "316   20190831  3호선   독립문    8877    8761  20190903\n",
      "315   20190831  3호선   무악재    3491    3576  20190903\n",
      "314   20190831  3호선    홍제   17306   16129  20190903\n",
      "313   20190831  3호선    녹번   11970    9936  20190903\n",
      "312   20190831  3호선    불광   16697   18805  20190903\n",
      "\n",
      "[18319 rows x 6 columns]\n",
      "        역명  노선명\n",
      "역ID            \n",
      "1872    매교  분당선\n",
      "1871  수원시청  분당선\n",
      "1870  매탄권선  분당선\n",
      "1869    망포  분당선\n",
      "1868    영통  분당선\n",
      "...    ...  ...\n",
      "316    독립문  3호선\n",
      "315    무악재  3호선\n",
      "314     홍제  3호선\n",
      "313     녹번  3호선\n",
      "312     불광  3호선\n",
      "\n",
      "[18319 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://github.com/silent0402/lecturenote/raw/master/Notes/data/subway.csv', \n",
    "                 sep=\",\",\n",
    "                index_col=2,\n",
    "                )\n",
    "print(df)\n",
    "df.shape\n",
    "#shape : 행, 열의 갯수\n",
    "df.columns\n",
    "#구체적인 열 정보\n",
    "\n",
    "df2 = df[[\"역명\", \"노선명\"]]\n",
    "print(df2)\n",
    "# 필요한 열만 뽑아내기 (두 개 이상일 경우 대괄호 두 개임을 주의)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### header가 없는 경우 & Delimiter(구분자)가 쉼표가 아닐 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       a   b\n",
      "0         사용일자,\"노선명\",\"역ID\",\"역명\",\"승차총승객수\",\"하차총승객수\",\"등록일자\" NaN\n",
      "1      20190801,\"분당선\",\"1872\",\"매교\",\"2348\",\"2405\",\"2019... NaN\n",
      "2      20190801,\"분당선\",\"1871\",\"수원시청\",\"11930\",\"13290\",\"... NaN\n",
      "3      20190801,\"분당선\",\"1870\",\"매탄권선\",\"4609\",\"4360\",\"20... NaN\n",
      "4      20190801,\"분당선\",\"1869\",\"망포\",\"14103\",\"13044\",\"20... NaN\n",
      "...                                                  ...  ..\n",
      "18315  20190831,\"3호선\",\"0316\",\"독립문\",\"8877\",\"8761\",\"201... NaN\n",
      "18316  20190831,\"3호선\",\"0315\",\"무악재\",\"3491\",\"3576\",\"201... NaN\n",
      "18317  20190831,\"3호선\",\"0314\",\"홍제\",\"17306\",\"16129\",\"20... NaN\n",
      "18318  20190831,\"3호선\",\"0313\",\"녹번\",\"11970\",\"9936\",\"201... NaN\n",
      "18319  20190831,\"3호선\",\"0312\",\"불광\",\"16697\",\"18805\",\"20... NaN\n",
      "\n",
      "[18320 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://github.com/silent0402/lecturenote/raw/master/Notes/data/subway.csv', \n",
    "                 sep=\"|\",\n",
    "                header=None,\n",
    "                 names=['a','b']\n",
    "                )\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel 파일 DataFrame에 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           사용일자  노선명   역ID    역명  승차총승객수  하차총승객수      등록일자\n",
      "0      20190801  분당선  1872    매교    2348    2405  20190804\n",
      "1      20190801  분당선  1871  수원시청   11930   13290  20190804\n",
      "2      20190801  분당선  1870  매탄권선    4609    4360  20190804\n",
      "3      20190801  분당선  1869    망포   14103   13044  20190804\n",
      "4      20190801  분당선  1868    영통    9303    9380  20190804\n",
      "...         ...  ...   ...   ...     ...     ...       ...\n",
      "18314  20190831  3호선   316   독립문    8877    8761  20190903\n",
      "18315  20190831  3호선   315   무악재    3491    3576  20190903\n",
      "18316  20190831  3호선   314    홍제   17306   16129  20190903\n",
      "18317  20190831  3호선   313    녹번   11970    9936  20190903\n",
      "18318  20190831  3호선   312    불광   16697   18805  20190903\n",
      "\n",
      "[18319 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('https://github.com/silent0402/lecturenote/raw/master/Notes/data/subway.xlsx', sheet_name=\"subway\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !wget 방법 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           사용일자  노선명   역ID    역명  승차총승객수  하차총승객수      등록일자\n",
      "0      20190801  분당선  1872    매교    2348    2405  20190804\n",
      "1      20190801  분당선  1871  수원시청   11930   13290  20190804\n",
      "2      20190801  분당선  1870  매탄권선    4609    4360  20190804\n",
      "3      20190801  분당선  1869    망포   14103   13044  20190804\n",
      "4      20190801  분당선  1868    영통    9303    9380  20190804\n",
      "...         ...  ...   ...   ...     ...     ...       ...\n",
      "18314  20190831  3호선   316   독립문    8877    8761  20190903\n",
      "18315  20190831  3호선   315   무악재    3491    3576  20190903\n",
      "18316  20190831  3호선   314    홍제   17306   16129  20190903\n",
      "18317  20190831  3호선   313    녹번   11970    9936  20190903\n",
      "18318  20190831  3호선   312    불광   16697   18805  20190903\n",
      "\n",
      "[18319 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('data/subway.xlsx', \n",
    "                   sheet_name = 'subway')\n",
    "\n",
    "print(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML 파일을 DataFrame에 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### url을 입력하여 해당 페이지의 Table 불러오기\n",
    "read_html의 결과로 DataFrame의 '리스트'가 반환되는 것에 유의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\yeongyun\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Bank Name        City  ST   CERT  \\\n",
      "0                                 The Enloe State Bank      Cooper  TX  10716   \n",
      "1                  Washington Federal Bank for Savings     Chicago  IL  30570   \n",
      "2      The Farmers and Merchants State Bank of Argonia     Argonia  KS  17719   \n",
      "3                                  Fayette County Bank  Saint Elmo  IL   1802   \n",
      "4    Guaranty Bank, (d/b/a BestBank in Georgia & Mi...   Milwaukee  WI  30003   \n",
      "..                                                 ...         ...  ..    ...   \n",
      "551                                 Superior Bank, FSB    Hinsdale  IL  32646   \n",
      "552                                Malta National Bank       Malta  OH   6629   \n",
      "553                    First Alliance Bank & Trust Co.  Manchester  NH  34264   \n",
      "554                  National State Bank of Metropolis  Metropolis  IL   3815   \n",
      "555                                   Bank of Honolulu    Honolulu  HI  21029   \n",
      "\n",
      "                   Acquiring Institution       Closing Date       Updated Date  \n",
      "0                     Legend Bank, N. A.       May 31, 2019    August 22, 2019  \n",
      "1                     Royal Savings Bank  December 15, 2017      July 24, 2019  \n",
      "2                            Conway Bank   October 13, 2017    August 12, 2019  \n",
      "3              United Fidelity Bank, fsb       May 26, 2017   January 29, 2019  \n",
      "4    First-Citizens Bank & Trust Company        May 5, 2017     March 22, 2018  \n",
      "..                                   ...                ...                ...  \n",
      "551                Superior Federal, FSB      July 27, 2001    August 19, 2014  \n",
      "552                    North Valley Bank        May 3, 2001  November 18, 2002  \n",
      "553  Southern New Hampshire Bank & Trust   February 2, 2001  February 18, 2003  \n",
      "554              Banterra Bank of Marion  December 14, 2000     March 17, 2005  \n",
      "555                   Bank of the Orient   October 13, 2000     March 17, 2005  \n",
      "\n",
      "[556 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://www.fdic.gov/bank/individual/failed/banklist.html'\n",
    "dfs = pd.read_html(url)\n",
    "print(dfs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON 파일을 DataFrame에 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미국 연도별 인구데이터 불러오기\n",
    "!wget 방식 미해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            indicator  \\\n",
      "0   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "1   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "2   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "3   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "4   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "5   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "6   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "7   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "8   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "9   {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "10  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "11  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "12  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "13  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "14  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "15  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "16  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "17  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "18  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "19  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "20  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "21  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "22  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "23  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "24  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "25  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "26  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "27  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "28  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "29  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "30  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "31  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "32  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "33  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "34  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "35  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "36  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "37  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "38  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "39  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "40  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "41  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "42  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "43  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "44  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "45  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "46  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "47  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "48  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "49  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "50  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "51  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "52  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "53  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "54  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "55  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "56  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "57  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "58  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
      "\n",
      "                                   country      value  decimal  date  \n",
      "0   {'id': 'US', 'value': 'United States'}  327167434        0  2018  \n",
      "1   {'id': 'US', 'value': 'United States'}  325147121        0  2017  \n",
      "2   {'id': 'US', 'value': 'United States'}  323071342        0  2016  \n",
      "3   {'id': 'US', 'value': 'United States'}  320742673        0  2015  \n",
      "4   {'id': 'US', 'value': 'United States'}  318386421        0  2014  \n",
      "5   {'id': 'US', 'value': 'United States'}  316057727        0  2013  \n",
      "6   {'id': 'US', 'value': 'United States'}  313874218        0  2012  \n",
      "7   {'id': 'US', 'value': 'United States'}  311580009        0  2011  \n",
      "8   {'id': 'US', 'value': 'United States'}  309326085        0  2010  \n",
      "9   {'id': 'US', 'value': 'United States'}  306771529        0  2009  \n",
      "10  {'id': 'US', 'value': 'United States'}  304093966        0  2008  \n",
      "11  {'id': 'US', 'value': 'United States'}  301231207        0  2007  \n",
      "12  {'id': 'US', 'value': 'United States'}  298379912        0  2006  \n",
      "13  {'id': 'US', 'value': 'United States'}  295516599        0  2005  \n",
      "14  {'id': 'US', 'value': 'United States'}  292805298        0  2004  \n",
      "15  {'id': 'US', 'value': 'United States'}  290107933        0  2003  \n",
      "16  {'id': 'US', 'value': 'United States'}  287625193        0  2002  \n",
      "17  {'id': 'US', 'value': 'United States'}  284968955        0  2001  \n",
      "18  {'id': 'US', 'value': 'United States'}  282162411        0  2000  \n",
      "19  {'id': 'US', 'value': 'United States'}  279040000        0  1999  \n",
      "20  {'id': 'US', 'value': 'United States'}  275854000        0  1998  \n",
      "21  {'id': 'US', 'value': 'United States'}  272657000        0  1997  \n",
      "22  {'id': 'US', 'value': 'United States'}  269394000        0  1996  \n",
      "23  {'id': 'US', 'value': 'United States'}  266278000        0  1995  \n",
      "24  {'id': 'US', 'value': 'United States'}  263126000        0  1994  \n",
      "25  {'id': 'US', 'value': 'United States'}  259919000        0  1993  \n",
      "26  {'id': 'US', 'value': 'United States'}  256514000        0  1992  \n",
      "27  {'id': 'US', 'value': 'United States'}  252981000        0  1991  \n",
      "28  {'id': 'US', 'value': 'United States'}  249623000        0  1990  \n",
      "29  {'id': 'US', 'value': 'United States'}  246819000        0  1989  \n",
      "30  {'id': 'US', 'value': 'United States'}  244499000        0  1988  \n",
      "31  {'id': 'US', 'value': 'United States'}  242289000        0  1987  \n",
      "32  {'id': 'US', 'value': 'United States'}  240133000        0  1986  \n",
      "33  {'id': 'US', 'value': 'United States'}  237924000        0  1985  \n",
      "34  {'id': 'US', 'value': 'United States'}  235825000        0  1984  \n",
      "35  {'id': 'US', 'value': 'United States'}  233792000        0  1983  \n",
      "36  {'id': 'US', 'value': 'United States'}  231664000        0  1982  \n",
      "37  {'id': 'US', 'value': 'United States'}  229466000        0  1981  \n",
      "38  {'id': 'US', 'value': 'United States'}  227225000        0  1980  \n",
      "39  {'id': 'US', 'value': 'United States'}  225055000        0  1979  \n",
      "40  {'id': 'US', 'value': 'United States'}  222585000        0  1978  \n",
      "41  {'id': 'US', 'value': 'United States'}  220239000        0  1977  \n",
      "42  {'id': 'US', 'value': 'United States'}  218035000        0  1976  \n",
      "43  {'id': 'US', 'value': 'United States'}  215973000        0  1975  \n",
      "44  {'id': 'US', 'value': 'United States'}  213854000        0  1974  \n",
      "45  {'id': 'US', 'value': 'United States'}  211909000        0  1973  \n",
      "46  {'id': 'US', 'value': 'United States'}  209896000        0  1972  \n",
      "47  {'id': 'US', 'value': 'United States'}  207661000        0  1971  \n",
      "48  {'id': 'US', 'value': 'United States'}  205052000        0  1970  \n",
      "49  {'id': 'US', 'value': 'United States'}  202677000        0  1969  \n",
      "50  {'id': 'US', 'value': 'United States'}  200706000        0  1968  \n",
      "51  {'id': 'US', 'value': 'United States'}  198712000        0  1967  \n",
      "52  {'id': 'US', 'value': 'United States'}  196560000        0  1966  \n",
      "53  {'id': 'US', 'value': 'United States'}  194303000        0  1965  \n",
      "54  {'id': 'US', 'value': 'United States'}  191889000        0  1964  \n",
      "55  {'id': 'US', 'value': 'United States'}  189242000        0  1963  \n",
      "56  {'id': 'US', 'value': 'United States'}  186538000        0  1962  \n",
      "57  {'id': 'US', 'value': 'United States'}  183691000        0  1961  \n",
      "58  {'id': 'US', 'value': 'United States'}  180671000        0  1960  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://github.com/silent0402/lecturenote/raw/master/Notes/data/population.json'\n",
    "\n",
    "df = pd.read_json(url)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json_normalize 함수를 이용하여 Nested structure의 JSON 파일을 정상적으로 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        value decimal  date indicator.id    indicator.value country.id  \\\n",
      "0   327167434       0  2018  SP.POP.TOTL  Population, total         US   \n",
      "1   325147121       0  2017  SP.POP.TOTL  Population, total         US   \n",
      "2   323071342       0  2016  SP.POP.TOTL  Population, total         US   \n",
      "3   320742673       0  2015  SP.POP.TOTL  Population, total         US   \n",
      "4   318386421       0  2014  SP.POP.TOTL  Population, total         US   \n",
      "5   316057727       0  2013  SP.POP.TOTL  Population, total         US   \n",
      "6   313874218       0  2012  SP.POP.TOTL  Population, total         US   \n",
      "7   311580009       0  2011  SP.POP.TOTL  Population, total         US   \n",
      "8   309326085       0  2010  SP.POP.TOTL  Population, total         US   \n",
      "9   306771529       0  2009  SP.POP.TOTL  Population, total         US   \n",
      "10  304093966       0  2008  SP.POP.TOTL  Population, total         US   \n",
      "11  301231207       0  2007  SP.POP.TOTL  Population, total         US   \n",
      "12  298379912       0  2006  SP.POP.TOTL  Population, total         US   \n",
      "13  295516599       0  2005  SP.POP.TOTL  Population, total         US   \n",
      "14  292805298       0  2004  SP.POP.TOTL  Population, total         US   \n",
      "15  290107933       0  2003  SP.POP.TOTL  Population, total         US   \n",
      "16  287625193       0  2002  SP.POP.TOTL  Population, total         US   \n",
      "17  284968955       0  2001  SP.POP.TOTL  Population, total         US   \n",
      "18  282162411       0  2000  SP.POP.TOTL  Population, total         US   \n",
      "19  279040000       0  1999  SP.POP.TOTL  Population, total         US   \n",
      "20  275854000       0  1998  SP.POP.TOTL  Population, total         US   \n",
      "21  272657000       0  1997  SP.POP.TOTL  Population, total         US   \n",
      "22  269394000       0  1996  SP.POP.TOTL  Population, total         US   \n",
      "23  266278000       0  1995  SP.POP.TOTL  Population, total         US   \n",
      "24  263126000       0  1994  SP.POP.TOTL  Population, total         US   \n",
      "25  259919000       0  1993  SP.POP.TOTL  Population, total         US   \n",
      "26  256514000       0  1992  SP.POP.TOTL  Population, total         US   \n",
      "27  252981000       0  1991  SP.POP.TOTL  Population, total         US   \n",
      "28  249623000       0  1990  SP.POP.TOTL  Population, total         US   \n",
      "29  246819000       0  1989  SP.POP.TOTL  Population, total         US   \n",
      "30  244499000       0  1988  SP.POP.TOTL  Population, total         US   \n",
      "31  242289000       0  1987  SP.POP.TOTL  Population, total         US   \n",
      "32  240133000       0  1986  SP.POP.TOTL  Population, total         US   \n",
      "33  237924000       0  1985  SP.POP.TOTL  Population, total         US   \n",
      "34  235825000       0  1984  SP.POP.TOTL  Population, total         US   \n",
      "35  233792000       0  1983  SP.POP.TOTL  Population, total         US   \n",
      "36  231664000       0  1982  SP.POP.TOTL  Population, total         US   \n",
      "37  229466000       0  1981  SP.POP.TOTL  Population, total         US   \n",
      "38  227225000       0  1980  SP.POP.TOTL  Population, total         US   \n",
      "39  225055000       0  1979  SP.POP.TOTL  Population, total         US   \n",
      "40  222585000       0  1978  SP.POP.TOTL  Population, total         US   \n",
      "41  220239000       0  1977  SP.POP.TOTL  Population, total         US   \n",
      "42  218035000       0  1976  SP.POP.TOTL  Population, total         US   \n",
      "43  215973000       0  1975  SP.POP.TOTL  Population, total         US   \n",
      "44  213854000       0  1974  SP.POP.TOTL  Population, total         US   \n",
      "45  211909000       0  1973  SP.POP.TOTL  Population, total         US   \n",
      "46  209896000       0  1972  SP.POP.TOTL  Population, total         US   \n",
      "47  207661000       0  1971  SP.POP.TOTL  Population, total         US   \n",
      "48  205052000       0  1970  SP.POP.TOTL  Population, total         US   \n",
      "49  202677000       0  1969  SP.POP.TOTL  Population, total         US   \n",
      "50  200706000       0  1968  SP.POP.TOTL  Population, total         US   \n",
      "51  198712000       0  1967  SP.POP.TOTL  Population, total         US   \n",
      "52  196560000       0  1966  SP.POP.TOTL  Population, total         US   \n",
      "53  194303000       0  1965  SP.POP.TOTL  Population, total         US   \n",
      "54  191889000       0  1964  SP.POP.TOTL  Population, total         US   \n",
      "55  189242000       0  1963  SP.POP.TOTL  Population, total         US   \n",
      "56  186538000       0  1962  SP.POP.TOTL  Population, total         US   \n",
      "57  183691000       0  1961  SP.POP.TOTL  Population, total         US   \n",
      "58  180671000       0  1960  SP.POP.TOTL  Population, total         US   \n",
      "\n",
      "    country.value  \n",
      "0   United States  \n",
      "1   United States  \n",
      "2   United States  \n",
      "3   United States  \n",
      "4   United States  \n",
      "5   United States  \n",
      "6   United States  \n",
      "7   United States  \n",
      "8   United States  \n",
      "9   United States  \n",
      "10  United States  \n",
      "11  United States  \n",
      "12  United States  \n",
      "13  United States  \n",
      "14  United States  \n",
      "15  United States  \n",
      "16  United States  \n",
      "17  United States  \n",
      "18  United States  \n",
      "19  United States  \n",
      "20  United States  \n",
      "21  United States  \n",
      "22  United States  \n",
      "23  United States  \n",
      "24  United States  \n",
      "25  United States  \n",
      "26  United States  \n",
      "27  United States  \n",
      "28  United States  \n",
      "29  United States  \n",
      "30  United States  \n",
      "31  United States  \n",
      "32  United States  \n",
      "33  United States  \n",
      "34  United States  \n",
      "35  United States  \n",
      "36  United States  \n",
      "37  United States  \n",
      "38  United States  \n",
      "39  United States  \n",
      "40  United States  \n",
      "41  United States  \n",
      "42  United States  \n",
      "43  United States  \n",
      "44  United States  \n",
      "45  United States  \n",
      "46  United States  \n",
      "47  United States  \n",
      "48  United States  \n",
      "49  United States  \n",
      "50  United States  \n",
      "51  United States  \n",
      "52  United States  \n",
      "53  United States  \n",
      "54  United States  \n",
      "55  United States  \n",
      "56  United States  \n",
      "57  United States  \n",
      "58  United States  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "with open ('population.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "\n",
    "df = json_normalize(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실시간 검색어 순위 JSON 데이터를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>keyword</th>\n",
       "      <th>change</th>\n",
       "      <th>score</th>\n",
       "      <th>tvalue</th>\n",
       "      <th>cvalue</th>\n",
       "      <th>ratio</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>커버낫 헝가리 구스</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>미세플라스틱 미검출 샤프란</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>미샤베스트1+1</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>투썸플레이스 원두</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>cjone 굿퀴즈</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>성현아</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>반트 1만개 이벤트</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>한승우</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>세리번나이트 오늘만 반값</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>미세플라스틱 섬유유연제</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>투썸 원두</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>플로이사프로모션</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>문근영</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>세리번 나이트</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>강희석</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>송진우</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>권용원</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>영화 1987</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>남동공단 화재</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>삼성생명 우리은행</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank         keyword change  score  tvalue  cvalue ratio  delta\n",
       "0      1      커버낫 헝가리 구스      +      0     0.0     0.0     .      0\n",
       "1      2  미세플라스틱 미검출 샤프란      +      0     0.0     0.0     .      0\n",
       "2      3        미샤베스트1+1      +      0     0.0     0.0     .      0\n",
       "3      4       투썸플레이스 원두      +      0     0.0     0.0     .      0\n",
       "4      5       cjone 굿퀴즈      +      0     0.0     0.0     .      0\n",
       "5      6             성현아      +      0     0.0     0.0     .      0\n",
       "6      7      반트 1만개 이벤트      +      0     0.0     0.0     .      0\n",
       "7      8             한승우      +      0     0.0     0.0     .      0\n",
       "8      9   세리번나이트 오늘만 반값      +      0     0.0     0.0     .      0\n",
       "9     10    미세플라스틱 섬유유연제      +      0     0.0     0.0     .      0\n",
       "10    11           투썸 원두      +      0     0.0     0.0     .      0\n",
       "11    12        플로이사프로모션      +      0     0.0     0.0     .      0\n",
       "12    13             문근영      +      0     0.0     0.0     .      0\n",
       "13    14         세리번 나이트      +      0     0.0     0.0     .      0\n",
       "14    15             강희석      +      0     0.0     0.0     .      0\n",
       "15    16             송진우      +      0     0.0     0.0     .      0\n",
       "16    17             권용원      +      0     0.0     0.0     .      0\n",
       "17    18         영화 1987      +      0     0.0     0.0     .      0\n",
       "18    19         남동공단 화재      +      0     0.0     0.0     .      0\n",
       "19    20       삼성생명 우리은행      +      0     0.0     0.0     .      0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json, requests\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "r = requests.get('http://rank.search.naver.com/rank.js')\n",
    "#json_normalize(json.loads(r.text), ['data','category'])\n",
    "json_normalize(json.loads(r.text), ['data','data'])\n",
    "#json_normalize(json.loads(r.text), ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-10-21T15:39:00+0900'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time stamp\n",
    "\n",
    "r = requests.get('http://rank.search.naver.com/rank.js')\n",
    "json.loads(r.text)['ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
